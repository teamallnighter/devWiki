<h1>Web Speech API</h1><div class="blockIndicator experimental indicator-warning"> <p> <strong>This is an <a href="https://developer.mozilla.org/en-US/docs/MDN/Contribute/Guidelines/Conventions_definitions#Experimental">experimental technology</a></strong><br>Check the <a href="#Browser_compatibility">Browser compatibility table</a> carefully before using this in production.</p> </div> <div class="summary"> <p>The Web Speech API enables you to incorporate voice data into web apps. The Web Speech API has two parts: SpeechSynthesis (Text-to-Speech), and SpeechRecognition (Asynchronous Speech Recognition.)</p> </div> <h2 id="Web_Speech_Concepts_and_Usage">Web Speech Concepts and Usage</h2> <p>The Web Speech API makes web apps able to handle voice data. There are two components to this API:</p> <ul> <li>Speech recognition is accessed via the <a href="speechrecognition"><code>SpeechRecognition</code></a> interface, which provides the ability to recognize voice context from an audio input (normally via the device's default speech recognition service) and respond appropriately. Generally you'll use the interface's constructor to create a new <a href="speechrecognition"><code>SpeechRecognition</code></a> object, which has a number of event handlers available for detecting when speech is input through the device's microphone. The <a href="speechgrammar"><code>SpeechGrammar</code></a> interface represents a container for a particular set of grammar that your app should recognise. Grammar is defined using <a href="http://www.w3.org/TR/jsgf/">JSpeech Grammar Format</a> (<strong>JSGF</strong>.)</li> <li>Speech synthesis is accessed via the <a href="speechsynthesis"><code>SpeechSynthesis</code></a> interface, a text-to-speech component that allows programs to read out their text content (normally via the device's default speech synthesiser.) Different voice types are represented by <a href="speechsynthesisvoice"><code>SpeechSynthesisVoice</code></a> objects, and different parts of text that you want to be spoken are represented by <a href="speechsynthesisutterance"><code>SpeechSynthesisUtterance</code></a> objects. You can get these spoken by passing them to the <a href="speechsynthesis/speak"><code>SpeechSynthesis.speak()</code></a> method.</li> </ul> <p>For more details on using these features, see <a href="web_speech_api/using_the_web_speech_api">Using the Web Speech API</a>.</p> <h2 id="Web_Speech_API_Interfaces">Web Speech API Interfaces</h2> <h3 id="Speech_recognition">Speech recognition</h3> <dl> <dt><a href="speechrecognition"><code>SpeechRecognition</code></a></dt> <dd>The controller interface for the recognition service; this also handles the <a href="speechrecognitionevent"><code>SpeechRecognitionEvent</code></a> sent from the recognition service.</dd> <dt><a href="speechrecognitionalternative"><code>SpeechRecognitionAlternative</code></a></dt> <dd>Represents a single word that has been recognised by the speech recognition service.</dd> <dt><a href="speechrecognitionerror"><code>SpeechRecognitionError</code></a></dt> <dd>Represents error messages from the recognition service.</dd> <dt><a href="speechrecognitionevent"><code>SpeechRecognitionEvent</code></a></dt> <dd>The event object for the <code><a href="https://developer.mozilla.org/en-US/docs/Web/Events/result">result</a></code> and <code><a href="https://developer.mozilla.org/en-US/docs/Web/Events/nomatch">nomatch</a></code> events, and contains all the data associated with an interim or final speech recognition result.</dd> <dt><a href="speechgrammar"><code>SpeechGrammar</code></a></dt> <dd>The words or patterns of words that we want the recognition service to recognize.</dd> <dt><a href="speechgrammarlist"><code>SpeechGrammarList</code></a></dt> <dd>Represents a list of <a href="speechgrammar"><code>SpeechGrammar</code></a> objects.</dd> <dt><a href="speechrecognitionresult"><code>SpeechRecognitionResult</code></a></dt> <dd>Represents a single recognition match, which may contain multiple <a href="speechrecognitionalternative"><code>SpeechRecognitionAlternative</code></a> objects.</dd> <dt><a href="speechrecognitionresultlist"><code>SpeechRecognitionResultList</code></a></dt> <dd>Represents a list of <a href="speechrecognitionresult"><code>SpeechRecognitionResult</code></a> objects, or a single one if results are being captured in <a href="speechrecognition/continuous"><code>continuous</code></a> mode.</dd> </dl> <h3 id="Speech_synthesis">Speech synthesis</h3> <dl> <dt><a href="speechsynthesis"><code>SpeechSynthesis</code></a></dt> <dd>The controller interface for the speech service; this can be used to retrieve information about the synthesis voices available on the device, start and pause speech, and other commands besides.</dd> <dt><a href="speechsynthesiserrorevent"><code>SpeechSynthesisErrorEvent</code></a></dt> <dd>Contains information about any errors that occur while processing <a href="speechsynthesisutterance"><code>SpeechSynthesisUtterance</code></a> objects in the speech service.</dd> <dt><a href="speechsynthesisevent"><code>SpeechSynthesisEvent</code></a></dt> <dd>Contains information about the current state of <a href="speechsynthesisutterance"><code>SpeechSynthesisUtterance</code></a> objects that have been processed in the speech service.</dd> <dt><a href="speechsynthesisutterance"><code>SpeechSynthesisUtterance</code></a></dt> <dd>Represents a speech request. It contains the content the speech service should read and information about how to read it (e.g. language, pitch and volume.)</dd> </dl> <dl> <dt><a href="speechsynthesisvoice"><code>SpeechSynthesisVoice</code></a></dt> <dd>Represents a voice that the system supports. Every <code>SpeechSynthesisVoice</code> has its own relative speech service including information about language, name and URI.</dd> <dt><a href="window/speechsynthesis"><code>Window.speechSynthesis</code></a></dt> <dd>Specced out as part of a <code>[NoInterfaceObject]</code> interface called <code>SpeechSynthesisGetter</code>, and Implemented by the <code>Window</code> object, the <code>speechSynthesis</code> property provides access to the <a href="speechsynthesis"><code>SpeechSynthesis</code></a> controller, and therefore the entry point to speech synthesis functionality.</dd> </dl> <h2 id="Examples">Examples</h2> <p>The <a href="https://github.com/mdn/web-speech-api/">Web Speech API repo</a> on GitHub contains demos to illustrate speech recognition and synthesis.</p> <h2 id="Specifications">Specifications</h2> <div class="_table"><table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a href="https://w3c.github.io/speech-api/" hreflang="en">Web Speech API</a></td> <td><span class="spec-Draft">Draft</span></td> <td>Initial definition</td> </tr> </tbody> </table></div> <h2 id="Browser_compatibility">Browser compatibility<a href="https://github.com/mdn/browser-compat-data" class="bc-github-link">Update compatibility data on GitHub</a><a href="https://github.com/mdn/browser-compat-data" class="bc-github-link">Update compatibility data on GitHub</a>
</h2> <h3 id="SpeechRecognition"><code>SpeechRecognition</code></h3>   <div class="_table">
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="6">Desktop</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Internet Explorer</th>
<th>Opera</th>
<th>Safari</th>
</tr>
</thead>
<tbody><tr>
<th scope="row">
<a href="https://developer.mozilla.org/docs/Web/API/SpeechRecognition">Basic support</a> 
</th>
<td class="bc-supports-yes bc-has-history"> 33<div class="bc-icons">Prefixed  </div>
<dl>
<dt class="bc-supports-yes bc-supports"> 33<div class="bc-icons">Prefixed  </div>
</dt>
<dd>Prefixed Implemented with the vendor prefix: webkit</dd>
<dd> You'll need to serve your code through a web server for recognition to work.</dd>
</dl>
</td>
<td> ? </td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-no"> No</td>
</tr></tbody>
</table>
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="7">Mobile</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Android webview</th>
<th>Chrome for Android</th>
<th>Edge Mobile</th>
<th>Firefox for Android</th>
<th>Opera for Android</th>
<th>iOS Safari</th>
<th>Samsung Internet</th>
</tr>
</thead>
<tbody><tr>
<th scope="row">
<a href="https://developer.mozilla.org/docs/Web/API/SpeechRecognition">Basic support</a> 
</th>
<td> ? </td>
<td class="bc-supports-yes bc-has-history"> Yes<div class="bc-icons">Prefixed  </div>
<dl>
<dt class="bc-supports-yes bc-supports"> Yes<div class="bc-icons">Prefixed  </div>
</dt>
<dd>Prefixed Implemented with the vendor prefix: webkit</dd>
<dd> You'll need to serve your code through a web server for recognition to work.</dd>
</dl>
</td>
<td> ? </td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-no"> No</td>
<td> ? </td>
</tr></tbody>
</table>
</div> <h3 id="SpeechSynthesis"><code>SpeechSynthesis</code></h3>  <div class="_table">
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="6">Desktop</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Internet Explorer</th>
<th>Opera</th>
<th>Safari</th>
</tr>
</thead>
<tbody><tr>
<th scope="row">
<a href="https://developer.mozilla.org/docs/Web/API/SpeechSynthesis">Basic support</a> 
</th>
<td class="bc-supports-yes"> 33</td>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes"> 49</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-yes"> 21</td>
<td class="bc-supports-yes"> 7</td>
</tr></tbody>
</table>
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="7">Mobile</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Android webview</th>
<th>Chrome for Android</th>
<th>Edge Mobile</th>
<th>Firefox for Android</th>
<th>Opera for Android</th>
<th>iOS Safari</th>
<th>Samsung Internet</th>
</tr>
</thead>
<tbody><tr>
<th scope="row">
<a href="https://developer.mozilla.org/docs/Web/API/SpeechSynthesis">Basic support</a> 
</th>
<td class="bc-supports-yes"> 4.4.3</td>
<td class="bc-supports-yes"> 33</td>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes bc-has-history"> 62
<dl>
<dt class="bc-supports-yes bc-supports"> 62
</dt>

<dt class="bc-supports-no bc-supports">61 — 62<div class="bc-icons">Disabled </div>
</dt>
<dd>Disabled From version 61 until version 62 (exclusive): this feature is behind the <code>media.webspeech.synth.enabled</code> preference (needs to be set to <code>true</code>). To change preferences in Firefox, visit about:config.</dd>
</dl>
</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-yes"> 7.1</td>
<td> ? </td>
</tr></tbody>
</table>
</div> <h2 id="See_also">See also</h2> <ul> <li><a href="web_speech_api/using_the_web_speech_api">Using the Web Speech API</a></li> <li><a href="http://www.sitepoint.com/talking-web-pages-and-the-speech-synthesis-api/">SitePoint article</a></li> <li><a href="http://updates.html5rocks.com/2014/01/Web-apps-that-talk---Introduction-to-the-Speech-Synthesis-API">HTML5Rocks article</a></li> <li>
<a href="http://aurelio.audero.it/demo/speech-synthesis-api-demo.html">Demo</a> [aurelio.audero.it]</li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2018 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API</a>
  </p>
</div>
