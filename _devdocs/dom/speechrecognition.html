<h1>SpeechRecognition</h1><p>{{APIRef（“Web Speech API”）}} {{SeeCompatTable}}</p> <p>在<code>SpeechRecognition</code>该界面<a href="web_speech_api">的Web语音API</a>是用于识别服务的控制器接口; 这也处理从识别服务发送的{{domxref（“SpeechRecognitionEvent”）}}。</p> <div class="note"> <p><strong>注意</strong>：在Chrome上，在网页上使用语音识别涉及基于服务器的识别引擎。您的音频将发送到Web服务进行识别处理，因此无法脱机工作。</p> </div> <h2 id="构造函数">构造函数</h2> <dl> <dt>{{domxref（ “SpeechRecognition.SpeechRecognition（）”）}}</dt> <dd>创建一个新<code>SpeechRecognition</code>对象。</dd> </dl> <h2 id="属性">属性</h2> <p><em><code>SpeechRecognition</code> 还从其父接口{{domxref（“EventTarget”）}}继承属性。</em></p> <dl> <dt>{{domxref（ “SpeechRecognition.grammars”）}}</dt> <dd>返回并设置{{domxref（“SpeechGrammar”）}}对象的集合，这些对象表示当前将理解的语法<code>SpeechRecognition</code>。</dd> <dt>{{domxref（ “SpeechRecognition.lang”）}}</dt> <dd>返回并设置当前语言<code>SpeechRecognition</code>。如果未指定，则默认为HTML {{htmlattrxref（“lang”，“html”）}}属性值，或者如果未设置，则默认为用户代理的语言设置。</dd> <dt>{{domxref（ “SpeechRecognition.continuous”）}}</dt> <dd>控制是为每个识别返回连续结果，还是仅返回单个结果。默认为单（<code>false</code>。）</dd> <dt>{{domxref（ “SpeechRecognition.interimResults”）}}</dt> <dd>控制是否应返回中间结果（<code>true</code>）或不返回（<code>false</code>。）中间结果是尚未最终的结果（例如{{domxref（“SpeechRecognitionResult.isFinal”）}}属性<code>false</code>。）</dd> <dt>{{domxref（ “SpeechRecognition.maxAlternatives”）}}</dt> <dd>设置每个结果提供的{{domxref（“SpeechRecognitionAlternative”）}}的最大数量。默认值为1。</dd> <dt>{{domxref（ “SpeechRecognition.serviceURI”）}}</dt> <dd>指定当前<code>SpeechRecognition</code>用于处理实际识别的语音识别服务的位置。默认值是用户代理的默认语音服务。</dd> </dl> <h3 id="事件处理程序">事件处理程序</h3> <dl> <dt>{{domxref（ “SpeechRecognition.onaudiostart”）}}</dt> <dd>用户代理开始捕获音频时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onaudioend”）}}</dt> <dd>用户代理完成捕获音频时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onend”）}}</dt> <dd>语音识别服务断开连接时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onerror”）}}</dt> <dd>发生语音识别错误时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onnomatch”）}}</dt> <dd>当语音识别服务返回没有明显识别的最终结果时触发。这可能涉及某种程度的识别，其不满足或超过{{domxref（“SpeechRecognitionAlternative.confidence”，“confidence”）}}阈值。</dd> <dt>{{domxref（ “SpeechRecognition.onresult”）}}</dt> <dd>当语音识别服务返回结果时触发 - 单词或短语已被肯定识别，并且已将其传送回应用程序。</dd> <dt>{{domxref（ “SpeechRecognition.onsoundstart”）}}</dt> <dd>在检测到任何声音可识别的语音时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onsoundend”）}}</dt> <dd>当任何声音 - 可辨认的语音 - 没有被发现时被触发。</dd> <dt>{{domxref（ “SpeechRecognition.onspeechstart”）}}</dt> <dd>当检测到语音识别服务识别为语音的声音时触发。</dd> <dt>{{domxref（ “SpeechRecognition.onspeechend”）}}</dt> <dd>当语音识别服务识别的语音已经停止被检测到时被触发。</dd> <dt>{{domxref（ “SpeechRecognition.onstart”）}}</dt> <dd>当语音识别服务已经开始收听传入音频时意图识别与当前相关联的语法<code>SpeechRecognition</code>。</dd> </dl> <h2 id="方法">方法</h2> <p><em><code>SpeechRecognition</code> 还从其父接口{{domxref（“EventTarget”）}}继承方法。</em></p> <dl> <dt>{{domxref（ “SpeechRecognition.abort（）”）}}</dt> <dd>停止语音识别服务监听传入音频，并且不会尝试返回{{domxref（“SpeechRecognitionResult”）}}。</dd> <dt>{{domxref（ “SpeechRecognition.start（）”）}}</dt> <dd>启动语音识别服务，听取传入的音频，意图识别与当前相关的语法<code>SpeechRecognition</code>。</dd> <dt>{{domxref（ “SpeechRecognition.stop（）”）}}</dt> <dd>停止语音识别服务监听传入音频，并尝试使用到目前为止捕获的音频返回{{domxref（“SpeechRecognitionResult”）}}。</dd> </dl> <h2 id="例子">例子</h2> <p>在我们简单的<a href="https://github.com/mdn/web-speech-api/tree/master/speech-color-changer">语音颜色转换器</a>示例中，我们<code>SpeechRecognition</code>使用{{domxref（“SpeechRecognition.SpeechRecognition”，“SpeechRecognition（）”）}}构造函数创建一个新的对象实例，创建一个新的{{domxref（“SpeechGrammarList”）}}，并将其设置为<code>SpeechRecognition</code>使用{{domxref（“SpeechRecognition.grammars”）}}属性的实例识别的语法。</p> <p>在定义了一些其他值之后，我们设置它以便在发生单击事件时启动识别服务（请参阅{{domxref（“SpeechRecognition.start（）”）}}。）当成功识别结果时， {{domxref（“SpeechRecognition.onresult”）}}处理程序触发，我们提取从事件对象中说出的颜色，然后将{{htmlelement（“html”）}}元素的背景颜色设置为该颜色。</p> <pre data-language="js">var grammar ='＃JSGF V1.0; 语法颜色; public &lt;color&gt; = aqua | azure | 米色| 浓汤| 黑色| 蓝色| 棕色| 巧克力| 珊瑚| 深红色| 青色| 紫红色| ghostwhite | 金| 一枝黄花| 灰色| 绿色| 靛蓝| 象牙| 卡其色| 薰衣草| 石灰| 亚麻| 洋红色| 栗色| 莫卡辛| 海军| 橄榄油| 橙色| 兰花| 秘鲁| 粉红色| 李子| 紫色| 红色| 三文鱼| sienna | 银| 雪| 晒黑| 蓝绿色| 蓟| 番茄| 绿松石| 紫罗兰| 白色| 黄色 ;'
var recognition = new SpeechRecognition（）;
var speechRecognitionList = new SpeechGrammarList（）;
speechRecognitionList.addFromString（grammar，1）;
recognition.grammars = speechRecognitionList;
//recognition.continuous = false;
recognition.lang ='en-US';
recognition.interimResults = false;
recognition.max替代品= 1;

var diagnostic = document.querySelector（'。output'）;
var bg = document.querySelector（'html'）;

document.body.onclick = function（）{
  recognition.start（）;
  console.log（'准备接收颜色命令。'）;
}

recognition.onresult = function（event）{
  var color = event.results [0] [0] .transcript;
  diagnostic.textContent ='收到的结果：'+ color;
  bg.style.backgroundColor = color;
}</pre> <h2 id="产品规格">产品规格</h2> <div class="_table"><table class="standard-table"> <tbody> <tr> <th scope="col">规格</th> <th scope="col">状态</th> <th scope="col">评论</th> </tr> <tr> <td>{{SpecName（'Web Speech API'，'＃speechreco-section'，'SpeechRecognition'）}}</td> <td>{{Spec2（'Web Speech API'）}}</td> <td> </td> </tr> </tbody> </table></div> <h2 id="浏览器兼容性">浏览器兼容性</h2>  <p>{{COMPAT（ “api.SpeechRecognition”）}}</p> <h3 id="Firefox_OS权限">Firefox OS权限</h3> <p>要在应用中使用语音识别，您需要在<a href="https://developer.mozilla.org/en-US/docs/Web/Apps/Build/Manifest">清单中</a>指定以下权限：</p> <pre data-language="json">“权限”：{
  “audio-capture”：{
    “description”：“音频捕捉”
  }，
  “语音识别” ： {
    “description”：“语音识别”
  }
}</pre> <p>您还需要一个特权应用，因此您还需要包含此应用：</p> <pre data-language="json">  “类型”：“特权”</pre> <h2 id="也可以看看">也可以看看</h2> <ul> <li><a href="web_speech_api">Web Speech API</a></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2018 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition</a>
  </p>
</div>
