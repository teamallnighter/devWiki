<h1>OfflineAudioContext.startRendering</h1> <p>The <code>startRendering()</code> method of the <a href="../offlineaudiocontext"><code>OfflineAudioContext</code></a> Interface starts rendering the audio graph, taking into account the current connections and the current scheduled changes.</p> <p>The <code><a href="https://developer.mozilla.org/en-US/docs/Web/Events/complete">complete</a></code> event (of type <a href="../offlineaudiocompletionevent"><code>OfflineAudioCompletionEvent</code></a>) is raised when the rendering is finished, containing the resulting <a href="../audiobuffer"><code>AudioBuffer</code></a> in its <code>renderedBuffer</code> property.</p>  <p>Browsers currently support two versions of the <code>startRendering()</code> method â€” an older event-based version and a newer promise-based version. The former will eventually be removed, but currently both mechanisms are provided for legacy reasons.</p>  <h2 id="Syntax">Syntax</h2> <p>Event-based version:</p> <pre class="syntaxbox">offlineAudioCtx.startRendering();
offlineAudioCtx.oncomplete = function(e) {
  // e.renderedBuffer contains the output buffer
}</pre> <p>Promise-based version:</p> <pre class="syntaxbox">offlineAudioCtx.startRendering().then(function(buffer) {
  // buffer contains the output buffer
});
</pre> <h3 id="Parameters">Parameters</h3> <p>None.</p> <h3 id="Returns">Returns</h3> <p>Void.</p> <h2 id="Example">Example</h2> <p>In this simple example, we declare both an <a href="../audiocontext"><code>AudioContext</code></a> and an <code>OfflineAudioContext</code> object. We use the <code>AudioContext</code> to load an audio track via XHR (<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/decodeAudioData"><code>AudioContext.decodeAudioData</code></a>), then the <code>OfflineAudioContext</code> to render the audio into an <a href="../audiobuffersourcenode"><code>AudioBufferSourceNode</code></a> and play the track through. After the offline audio graph is set up, you need to render it to an <a href="../audiobuffer"><code>AudioBuffer</code></a> using <a href="startrendering"><code>OfflineAudioContext.startRendering</code></a>.</p> <p>When the <code>startRendering()</code> promise resolves, rendering has completed and the output <code>AudioBuffer</code> is returned out of the promise.</p> <p>At this point we create another audio context, create an <a href="../audiobuffersourcenode"><code>AudioBufferSourceNode</code></a> inside it, and set its buffer to be equal to the promise <code>AudioBuffer</code>. This is then played as part of a simple standard audio graph.</p> <div class="note"> <p><strong>Note</strong>: For a working example, see our <a href="https://mdn.github.io/webaudio-examples/offline-audio-context-promise/">offline-audio-context-promise</a> Github repo (see the <a href="https://github.com/mdn/webaudio-examples">source code</a> too.)</p> </div> <pre data-language="js">// define online and offline audio context

var audioCtx = new AudioContext();
var offlineCtx = new OfflineAudioContext(2,44100*40,44100);

source = offlineCtx.createBufferSource();

// use XHR to load an audio track, and
// decodeAudioData to decode it and OfflineAudioContext to render it

function getData() {
  request = new XMLHttpRequest();

  request.open('GET', 'viper.ogg', true);

  request.responseType = 'arraybuffer';

  request.onload = function() {
    var audioData = request.response;

    audioCtx.decodeAudioData(audioData, function(buffer) {
      myBuffer = buffer;
      source.buffer = myBuffer;
      source.connect(offlineCtx.destination);
      source.start();
      //source.loop = true;
      offlineCtx.startRendering().then(function(renderedBuffer) {
        console.log('Rendering completed successfully');
        var audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        var song = audioCtx.createBufferSource();
        song.buffer = renderedBuffer;

        song.connect(audioCtx.destination);

        play.onclick = function() {
          song.start();
        }
      }).catch(function(err) {
          console.log('Rendering failed: ' + err);
          // Note: The promise should reject when startRendering is called a second time on an OfflineAudioContext
      });
    });
  }

  request.send();
}

// Run getData to start the process off

getData();</pre> <h2 id="Specifications">Specifications</h2> <div class="_table"><table class="standard-table"> <tbody> <tr> <th scope="col">Specification</th> <th scope="col">Status</th> <th scope="col">Comment</th> </tr> <tr> <td><a href="https://webaudio.github.io/web-audio-api/#widl-OfflineAudioContext-startRendering-Promise-AudioBuffer" hreflang="en">Web Audio API<br><small>The definition of 'startRendering()' in that specification.</small></a></td> <td><span class="spec-WD">Working Draft</span></td> <td> </td> </tr> </tbody> </table></div> <h2 id="Browser_compatibility">Browser compatibility<a href="https://github.com/mdn/browser-compat-data" class="bc-github-link">Update compatibility data on GitHub</a>
</h2>   <div class="_table">
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="6">Desktop</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Chrome</th>
<th>Edge</th>
<th>Firefox</th>
<th>Internet Explorer</th>
<th>Opera</th>
<th>Safari</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">Basic support</th>
<td class="bc-supports-yes"> 14</td>
<td class="bc-supports-yes"> 12</td>
<td class="bc-supports-yes"> 25</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-yes"> 15</td>
<td class="bc-supports-yes"> 6</td>
</tr>
<tr>
<th scope="row">Promise-based <code>startRendering()</code>
</th>
<td class="bc-supports-yes"> 42</td>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes"> 37</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-yes"> 29</td>
<td class="bc-supports-no"> No</td>
</tr>
</tbody>
</table>
<table class="bc-table bc-table-web">
<thead>
<tr class="bc-platforms">
<th></th>
<th colspan="7">Mobile</th>
</tr>
<tr class="bc-browsers">
<th></th>
<th>Android webview</th>
<th>Chrome for Android</th>
<th>Edge Mobile</th>
<th>Firefox for Android</th>
<th>Opera for Android</th>
<th>iOS Safari</th>
<th>Samsung Internet</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">Basic support</th>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes"> 18</td>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes"> 26</td>
<td class="bc-supports-yes"> 15</td>
<td> ? </td>
<td class="bc-supports-yes"> Yes</td>
</tr>
<tr>
<th scope="row">Promise-based <code>startRendering()</code>
</th>
<td class="bc-supports-yes"> 42</td>
<td class="bc-supports-yes"> 42</td>
<td class="bc-supports-yes"> Yes</td>
<td class="bc-supports-yes"> 37</td>
<td class="bc-supports-yes"> 29</td>
<td class="bc-supports-no"> No</td>
<td class="bc-supports-yes"> 4.0</td>
</tr>
</tbody>
</table>
</div>  <h2 id="See_also">See also</h2> <ul> <li><a href="https://developer.mozilla.org/en-US/docs/Web_Audio_API/Using_Web_Audio_API">Using the Web Audio API</a></li> </ul><div class="_attribution">
  <p class="_attribution-p">
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering$edit" class="_attribution-link">Edit this page on MDN</a>
  </p>
</div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2018 Mozilla Developer Network and individual contributors.<br>Licensed under the Creative Commons Attribution-ShareAlike License v2.5 or later.<br>
    <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering" class="_attribution-link">https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext/startRendering</a>
  </p>
</div>
